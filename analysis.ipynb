{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "# import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn k means clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/choice.db')\n",
    "query = 'SELECT posting_date FROM prediction'\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donation needs to be ordered by date, consider date format.\n",
    "\n",
    "Date samples:\n",
    "0   01/08/2003\n",
    "1   01/08/2003\n",
    "2   01/08/2003\n",
    "3   01/08/2003\n",
    "4   12/20/2002\n",
    "5   12/20/2002\n",
    "6   12/20/2002\n",
    "7   12/27/2002\n",
    "8   12/27/2002\n",
    "9   12/27/2002\n",
    "\n",
    "Now in terms of df timestamp.\n",
    "\n",
    "Consider excluding donations from natural disasters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize donation trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/choice.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "donor_totals_query = \"\"\"\n",
    "SELECT donor_id, COUNT(*)\n",
    "FROM prediction\n",
    "GROUP BY donor_id\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(donor_totals_query)\n",
    "donor_totals = cursor.fetchall()\n",
    "\n",
    "print(donor_totals)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge variety of giving frequencies, once to thousands. Reflects the literature.\n",
    "\n",
    "[(None, 88), ('8thAvenue', 15), ('AGRUSA', 1), ('Abbott', 1614), ('Aldi', 3), ('AllenCanning', 51), ('Armour', 26), ('Athens', 169), ('Atlanta', 699), ('Augusta', 46), ('B&G', 11), ('Barilla', 4988), ('BasicAmerican', 31), ('Bayer', 196), ('Blue Diamond Growers', 42), ('Brill', 10), ('Bumblebee', 54), ('Califia', 6), ('CampbellSoup', 4), ('Cargill', 3), ('Chairmans Foods', 7), ('Chicken of the sea', 1), ('ChickfilA', 3), ('Chobani', 14), ('Clorox', 181), ('CocaCola', 11), ('ConAgraDairy', 426), ('ConAgraFoods', 17444), ('ConAgraFrozen', 837), ('ConAgraGrocery', 1146), ('ConAgraLogistics', 7), ('ConAgraPotato', 2125), ('ConAgraRefrigerated', 9), ('ConAgraSnackFoods', 6), ('Consorzi', 5), ('Continental', 184), ('Danone', 79), ('Delmontefoods', 32), ('DiamondFoods', 42), ('Dole', 151), ('Dunkin', 2), ('Duracell', 30), ('Faribault', 3), ('FarmlandFoods', 2), ('Freiberger', 65), ('Frito', 5), ('GHOST', 26), ('GMILLS', 1808), ('Gmills', 64), ('Headquarters', 12), ('Heinz', 624), ('Henkel', 268), ('HersheyChocolate', 898), ('Hersheychocolate', 48), ('Hormel', 2), ('JRSIMPLOT', 7), ('JohnMorrell', 13), ('Johnson', 23), ('KRAFT', 50698), ('KaChava', 3), ('Karlin', 1), ('Kdrp', 21), ('Kellogg', 174912), ('Kenvue', 183), ('Kikkoman', 38), ('KimClark', 12), ('Kinkos', 13), ('Kraft', 58057), ('KraftBiscuit', 5905), ('LDSChurch', 10), ('LambWeston', 153), ('LandOLakes', 146), ('Lopez Foods', 13), ('MONDELEZ', 22379), ('Macon', 84), ('Mars', 52), ('MarsFood', 200), ('McCainFoods', 75), ('McDonalds', 2), ('MilwaukeeZC', 2), ('Mondelez', 17880), ('Morton', 53), ('NESTLE', 20), ('Nestle', 1994), ('NestleHandHeld', 88), ('Newman', 44), ('Niagara', 17), ('Nutrisystem', 47), ('OceanSpray', 55), ('PACIFICCOASTPRODUCERS', 41), ('PEPSI', 9), ('PGCompany', 14845), ('Panera', 61), ('PatrickCudahy', 4), ('Penske', 2), ('PenskeTX', 60), ('PerdueFarms', 87), ('PinnacleFood', 711), ('Plexus Worldwide', 7), ('PremierNutrition', 137), ('Quaker', 10079), ('RiseBaking', 2), ('SCJohnson', 11), ('SEASHARE', 1), ('SENECA', 1), ('STARBUCKS', 7), ('SaraLeeFB', 44), ('Savannah', 17), ('Schreiber', 149), ('SchwansBakery', 29), ('SchwansFoodServ', 133), ('SchwansGlobal', 16), ('SeaShare', 21), ('Seneca', 63), ('SmithfieldPacking', 4), ('Smithfieldfoods', 8), ('South Beach LLC', 17), ('SouthBeach', 103), ('Southeasternmills', 63), ('StarRDC', 47), ('StarSuppliers', 191), ('Starbucks', 20), ('Sunsweet', 45), ('The Honey Pot Co', 16), ('Tradex', 7), ('TreeHouse', 239), ('TreeHouseFoods', 2035), ('TreeHousePrivateBrands', 2), ('Treehouse', 3), ('Tropicana', 39), ('Tyson', 991), ('UNFI', 23), ('UncleBens', 362), ('Unclebens', 4), ('Unilever', 6), ('Valdosta', 905), ('VictoryPackaging', 4), ('VisualPak', 3), ('VitaCoco', 4), ('WALGREEN', 1), ('WALMART', 16), ('WKKellogg', 69), ('WRIGLEY', 41), ('Walgreen', 242), ('Welchs', 11), ('Wendys', 7), ('WestonFoods', 47), ('Wrigley', 1237), ('Yowie', 10), ('advance', 491), ('aldi', 1), ('aryzta', 1), ('bayer', 23), ('continental', 4), ('cott', 6), ('danone', 8), ('diamondfoods', 32), ('dollargeneral', 5), ('dollartree', 2), ('duracell', 177), ('fano', 4), ('fini', 3), ('frito', 3), ('gmills', 627), ('greenleaf', 6), ('happyhealthy', 75), ('kingarthur', 23), ('kings', 31), ('kraft', 796), ('lambweston', 313), ('mars', 10), ('mondelez', 261), ('nestle', 220), ('panera', 7), ('pgcompany', 70), ('postconsumer', 180), ('scjohnson', 317), ('smucker', 1415), ('snyders', 30), ('starsuppliers', 2), ('sysco', 2), ('target', 1), ('tivityhealth', 1), ('tradex', 14), ('treehouse', 65), ('unclebens', 5), ('voss', 112), ('walgreen', 42), ('wrigley', 48)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reliability score for donors.\n",
    "\n",
    "Binary variable of donor/month.\n",
    "\n",
    "Each donor needs a column over the entire time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/choice.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "columns = \"\"\"\n",
    "SELECT *\n",
    "FROM prediction\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(columns)\n",
    "donor_totals = cursor.fetchall()\n",
    "\n",
    "print(donor_totals)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/choice.db')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM prediction\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order\n",
    "\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'])\n",
    "df['year'] = df['posting_date'].dt.year\n",
    "df['month'] = df['posting_date'].dt.month\n",
    "\n",
    "df = df.sort_values(by=['year', 'month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['donor_id'], dtype=int)\n",
    "\n",
    "df_numeric = df_encoded.select_dtypes(include='number').copy()\n",
    "\n",
    "df_numeric['year'] = df_encoded['year']\n",
    "df_numeric['month'] = df_encoded['month']\n",
    "\n",
    "df_grouped = df_numeric.groupby(['year', 'month'], as_index=True).sum()\n",
    "\n",
    "with open('donor_encoding.csv', 'w') as f:\n",
    "    f.write(df_grouped.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_grouped.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_grouped.drop('gross_weight', axis=1)\n",
    "df = df.applymap(lambda x: 1 if x != 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df.sum(axis=0)\n",
    "df_e = df_sum.divide(188)\n",
    "\n",
    "with open('df_e.csv', 'w') as f:\n",
    "    f.write(df_e.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_e, bins=15, range=[0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of donation frequency is similar to some locations from the paper, fewer truly consistent donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change shape of data for k means clustering\n",
    "\n",
    "print(df_e)\n",
    "print(df_e.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.DataFrame(df_e)\n",
    "\n",
    "e_scaled = StandardScaler().fit_transform(df)\n",
    "\n",
    "inertia = []\n",
    "k_range = range(1, 20)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(e_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.title(\"Elbow Method to Determine Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (Within-Cluster Sum of Squares)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# optimal k at 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn, split dataset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
